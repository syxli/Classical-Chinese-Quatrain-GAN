{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf63599d-ecbf-4515-bef6-506278d36811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0905c7b4-474d-4aab-b340-80378b47e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry = pd.read_csv('../data/quatrains_w_info.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284ee300-691f-47c5-8c90-db5860b54048",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pd.read_csv('../data/dictionary_cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b0559e3-db6a-4fdb-9ed7-e0a2d037c553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>meter_score</th>\n",
       "      <th>rhyme</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>澄潭皎鏡石崔巍萬壑千岩暗綠苔林亭自有幽貞趣況複秋深爽氣來</td>\n",
       "      <td>[3497, 3485, 4137, 7002, 4278, 1538, 1605, 552...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>憶昔嬌妃在紫宸鉛華不禦得天真霜綃雖似當時態爭奈嬌波不顧人</td>\n",
       "      <td>[2064, 2534, 1323, 1208, 999, 4802, 1392, 6911...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>刻木牽絲作老翁雞皮鶴發與真同須臾弄罷寂無事還似人生一夢中</td>\n",
       "      <td>[514, 2654, 3752, 4841, 211, 5096, 5066, 7204,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>禁苑秋來爽氣多昆明風動起滄波中流簫鼓誠堪賞詎假橫汾發棹歌</td>\n",
       "      <td>[4400, 5391, 4433, 231, 3722, 3133, 1159, 2526...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>大殿連雲接爽溪鐘聲還與鼓聲齊長安若問江南事說道風光在水西</td>\n",
       "      <td>[1164, 3097, 6651, 7211, 2275, 3722, 3410, 700...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62206</th>\n",
       "      <td>故園東望路漫漫雙袖龍鍾淚不乾馬上相逢無紙筆憑君傳語報平安</td>\n",
       "      <td>[2431, 989, 2691, 2648, 6428, 3461, 3461, 7200...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62207</th>\n",
       "      <td>黃沙磧裏客行迷四望雲天直下低爲言地盡天還盡行到安西更向西</td>\n",
       "      <td>[7860, 3185, 4344, 5971, 1380, 5916, 6622, 971...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62208</th>\n",
       "      <td>西向輪臺萬里馀也知鄉信日應疎隴山鸚鵡能言語爲報家人數寄書</td>\n",
       "      <td>[6037, 719, 6556, 5294, 5528, 6875, 7478, 111,...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62209</th>\n",
       "      <td>朱脣一點桃花殷宿妝嬌羞偏髻鬟細看只似陽臺女醉着莫許歸巫山</td>\n",
       "      <td>[2660, 5210, 67, 7876, 2778, 5381, 3092, 1394,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62210</th>\n",
       "      <td>常聞嬴女玉簫臺奏曲情深彩鳳來欲登此地銷歸恨却羨雙飛去不回</td>\n",
       "      <td>[1658, 5129, 1332, 1201, 3844, 4693, 5294, 118...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62211 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text  \\\n",
       "0      澄潭皎鏡石崔巍萬壑千岩暗綠苔林亭自有幽貞趣況複秋深爽氣來   \n",
       "1      憶昔嬌妃在紫宸鉛華不禦得天真霜綃雖似當時態爭奈嬌波不顧人   \n",
       "2      刻木牽絲作老翁雞皮鶴發與真同須臾弄罷寂無事還似人生一夢中   \n",
       "3      禁苑秋來爽氣多昆明風動起滄波中流簫鼓誠堪賞詎假橫汾發棹歌   \n",
       "4      大殿連雲接爽溪鐘聲還與鼓聲齊長安若問江南事說道風光在水西   \n",
       "...                             ...   \n",
       "62206  故園東望路漫漫雙袖龍鍾淚不乾馬上相逢無紙筆憑君傳語報平安   \n",
       "62207  黃沙磧裏客行迷四望雲天直下低爲言地盡天還盡行到安西更向西   \n",
       "62208  西向輪臺萬里馀也知鄉信日應疎隴山鸚鵡能言語爲報家人數寄書   \n",
       "62209  朱脣一點桃花殷宿妝嬌羞偏髻鬟細看只似陽臺女醉着莫許歸巫山   \n",
       "62210  常聞嬴女玉簫臺奏曲情深彩鳳來欲登此地銷歸恨却羨雙飛去不回   \n",
       "\n",
       "                                                  tokens  meter_score  rhyme  \\\n",
       "0      [3497, 3485, 4137, 7002, 4278, 1538, 1605, 552...          1.0      1   \n",
       "1      [2064, 2534, 1323, 1208, 999, 4802, 1392, 6911...          1.0      1   \n",
       "2      [514, 2654, 3752, 4841, 211, 5096, 5066, 7204,...          1.0      1   \n",
       "3      [4400, 5391, 4433, 231, 3722, 3133, 1159, 2526...          0.5      1   \n",
       "4      [1164, 3097, 6651, 7211, 2275, 3722, 3410, 700...          1.0      1   \n",
       "...                                                  ...          ...    ...   \n",
       "62206  [2431, 989, 2691, 2648, 6428, 3461, 3461, 7200...          0.5      1   \n",
       "62207  [7860, 3185, 4344, 5971, 1380, 5916, 6622, 971...          1.0      1   \n",
       "62208  [6037, 719, 6556, 5294, 5528, 6875, 7478, 111,...          0.5      1   \n",
       "62209  [2660, 5210, 67, 7876, 2778, 5381, 3092, 1394,...          1.0      1   \n",
       "62210  [1658, 5129, 1332, 1201, 3844, 4693, 5294, 118...          1.0      1   \n",
       "\n",
       "       target  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "62206       1  \n",
       "62207       1  \n",
       "62208       1  \n",
       "62209       1  \n",
       "62210       1  \n",
       "\n",
       "[62211 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e87c468-9bc6-4cc0-a069-3b8eadfbd004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char</th>\n",
       "      <th>tone</th>\n",
       "      <th>rime</th>\n",
       "      <th>ipa</th>\n",
       "      <th>tone_class</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>jyutping</th>\n",
       "      <th>hangul</th>\n",
       "      <th>rime_index</th>\n",
       "      <th>meter_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>用</td>\n",
       "      <td>去</td>\n",
       "      <td>用</td>\n",
       "      <td>yowng</td>\n",
       "      <td>H</td>\n",
       "      <td>yòng</td>\n",
       "      <td>jung6</td>\n",
       "      <td>용</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>甪</td>\n",
       "      <td>入</td>\n",
       "      <td>屋</td>\n",
       "      <td>luwk</td>\n",
       "      <td>E</td>\n",
       "      <td>lù</td>\n",
       "      <td>luk6</td>\n",
       "      <td>녹</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>甫</td>\n",
       "      <td>上</td>\n",
       "      <td>麌</td>\n",
       "      <td>pju</td>\n",
       "      <td>X</td>\n",
       "      <td>fǔ</td>\n",
       "      <td>fu2</td>\n",
       "      <td>보</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>甬</td>\n",
       "      <td>上</td>\n",
       "      <td>腫</td>\n",
       "      <td>yowng</td>\n",
       "      <td>X</td>\n",
       "      <td>yǒng</td>\n",
       "      <td>jung2</td>\n",
       "      <td>용</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>甯</td>\n",
       "      <td>去</td>\n",
       "      <td>徑</td>\n",
       "      <td>neng</td>\n",
       "      <td>H</td>\n",
       "      <td>níng</td>\n",
       "      <td>ning4</td>\n",
       "      <td>영</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>田</td>\n",
       "      <td>平</td>\n",
       "      <td>先</td>\n",
       "      <td>den</td>\n",
       "      <td>L</td>\n",
       "      <td>tián</td>\n",
       "      <td>tin4</td>\n",
       "      <td>전</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>由</td>\n",
       "      <td>平</td>\n",
       "      <td>尤</td>\n",
       "      <td>yuw</td>\n",
       "      <td>L</td>\n",
       "      <td>yóu</td>\n",
       "      <td>jau4</td>\n",
       "      <td>유</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>甲</td>\n",
       "      <td>入</td>\n",
       "      <td>狎</td>\n",
       "      <td>kaep</td>\n",
       "      <td>E</td>\n",
       "      <td>jiǎ</td>\n",
       "      <td>gaap3</td>\n",
       "      <td>갑</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>申</td>\n",
       "      <td>平</td>\n",
       "      <td>眞</td>\n",
       "      <td>syin</td>\n",
       "      <td>L</td>\n",
       "      <td>shēn</td>\n",
       "      <td>san1</td>\n",
       "      <td>신</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>男</td>\n",
       "      <td>平</td>\n",
       "      <td>覃</td>\n",
       "      <td>nom</td>\n",
       "      <td>L</td>\n",
       "      <td>nán</td>\n",
       "      <td>naam4</td>\n",
       "      <td>남</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>甸</td>\n",
       "      <td>去</td>\n",
       "      <td>霰</td>\n",
       "      <td>den</td>\n",
       "      <td>H</td>\n",
       "      <td>diàn</td>\n",
       "      <td>din6</td>\n",
       "      <td>전</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>町</td>\n",
       "      <td>平</td>\n",
       "      <td>青</td>\n",
       "      <td>theng</td>\n",
       "      <td>L</td>\n",
       "      <td>tǐng</td>\n",
       "      <td>ting5</td>\n",
       "      <td>정</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>甽</td>\n",
       "      <td>上</td>\n",
       "      <td>銑</td>\n",
       "      <td>kwen</td>\n",
       "      <td>X</td>\n",
       "      <td>quǎn</td>\n",
       "      <td>hyun2</td>\n",
       "      <td>견</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>甿</td>\n",
       "      <td>平</td>\n",
       "      <td>耕</td>\n",
       "      <td>meang</td>\n",
       "      <td>L</td>\n",
       "      <td>méng</td>\n",
       "      <td>maang4</td>\n",
       "      <td>맹</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>畀</td>\n",
       "      <td>去</td>\n",
       "      <td>至</td>\n",
       "      <td>pjij</td>\n",
       "      <td>H</td>\n",
       "      <td>bì</td>\n",
       "      <td>bei2</td>\n",
       "      <td>비</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     char tone rime    ipa tone_class pinyin jyutping hangul  rime_index  \\\n",
       "4000    用    去    用  yowng          H   yòng    jung6      용           1   \n",
       "4001    甪    入    屋   luwk          E     lù     luk6      녹           1   \n",
       "4002    甫    上    麌    pju          X     fǔ      fu2      보           4   \n",
       "4003    甬    上    腫  yowng          X   yǒng    jung2      용           1   \n",
       "4004    甯    去    徑   neng          H   níng    ning4      영          12   \n",
       "4005    田    平    先    den          L   tián     tin4      전           7   \n",
       "4006    由    平    尤    yuw          L    yóu     jau4      유          14   \n",
       "4007    甲    入    狎   kaep          E    jiǎ    gaap3      갑          16   \n",
       "4008    申    平    眞   syin          L   shēn     san1      신           6   \n",
       "4009    男    平    覃    nom          L    nán    naam4      남          16   \n",
       "4010    甸    去    霰    den          H   diàn     din6      전           7   \n",
       "4011    町    平    青  theng          L   tǐng    ting5      정          12   \n",
       "4012    甽    上    銑   kwen          X   quǎn    hyun2      견           7   \n",
       "4013    甿    平    耕  meang          L   méng   maang4      맹          12   \n",
       "4014    畀    去    至   pjij          H     bì     bei2      비           3   \n",
       "\n",
       "      meter_class  \n",
       "4000            0  \n",
       "4001            0  \n",
       "4002            0  \n",
       "4003            0  \n",
       "4004            0  \n",
       "4005            1  \n",
       "4006            1  \n",
       "4007            0  \n",
       "4008            1  \n",
       "4009            1  \n",
       "4010            0  \n",
       "4011            1  \n",
       "4012            0  \n",
       "4013            1  \n",
       "4014            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.iloc[4000:4015,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf678197-3ec5-444b-80f6-f49bd5a84d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = {dictionary.char[i]: i for i in range(0,len(dictionary))}\n",
    "char_dict = {i: {'char': dictionary.char[i],\n",
    "                 'tone': dictionary.tone_class[i],\n",
    "                 'rime': dictionary.rime_index[i],\n",
    "                 'meter': dictionary.meter_class[i]\n",
    "                 } for i in range(0,len(dictionary))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6dbbe87a-016d-4fae-bfe6-42cad51c456d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7980"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865f6308-68a6-4fe4-a92f-d56adf97d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "meters = [\n",
    "    [1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1,\n",
    "     0,0,1,1,0,0,1,\n",
    "     1,1,0,0,0,1,1],\n",
    "    [0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1,\n",
    "     1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1],\n",
    "    [1,1,0,0,0,1,1,\n",
    "     0,0,1,1,0,0,1,\n",
    "     0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1],\n",
    "    [0,0,1,1,0,0,1,\n",
    "     1,1,0,0,0,1,1,\n",
    "     1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1],\n",
    "    [0,0,1,1,0,0,1,\n",
    "     1,1,0,0,0,1,1,\n",
    "     1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1],\n",
    "    [1,1,0,0,0,1,1,\n",
    "     0,0,1,1,0,0,1,\n",
    "     0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1],\n",
    "    [0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1,\n",
    "     1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1],\n",
    "    [1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1,\n",
    "     0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523c016e-62d3-47cb-9bfb-53846cd7392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenizer(text):\n",
    "    return [chars[i] for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa66e12-f4d8-4941-aa22-602374a640cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_text(tokens):\n",
    "    return ''.join([char_dict[i]['char'] for i in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39658bcd-bb3e-4746-9c4d-3cc6ea46c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyme_checker(tokens):\n",
    "    if char_dict[tokens[13]]['rime'] == char_dict[tokens[27]]['rime']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86c84dae-5225-450f-816e-bf19edb55a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_meter(tokens):\n",
    "    return [char_dict[i]['meter'] for i in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87fb12ed-dd26-43ad-b0f4-bd7a2d63f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meter_score(tokens):\n",
    "    meter = [char_dict[i]['meter'] for i in tokens]\n",
    "    scores = []\n",
    "    for n in meters:\n",
    "        scores.append(sum([int(meter[num]==n[num]) for num in n]))\n",
    "    return max(scores)/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a03a76-7069-4083-a5ab-40295ba14561",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry.tokens = poetry.text.apply(text_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80872e9d-8b25-422f-b5e2-d0ea822e8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,Embedding\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16d6f615-a97b-4657-8e44-a9e9973dfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efc1f5bd-6454-47f0-92be-0cbccd65ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencer(tokens, train_len):\n",
    "    sequences = []\n",
    "    for i in range(train_len, len(tokens)):\n",
    "        seq = tokens[i-train_len: i]\n",
    "        sequences.append(seq)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75512db2-03a7-416b-89fc-3ada89b68824",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_list = []\n",
    "for i in poetry.tokens:\n",
    "    sequence_list += sequencer(i, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca914485-fdd7-40a2-b0e4-5d92f5d9cab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1244220"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ea82ce8-d25c-4669-8baa-774b21d38a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_list = np.array(sequence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4f4fb4f-70c8-4cde-b13e-842b1b4dcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb7e0b99-b92f-4dd9-a27c-f566ba528827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7980"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a705d1-242e-44ad-81c9-96a57e8ae869",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequence_list[:,:-1]\n",
    "y = sequence_list[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91cf7962-0f38-4c28-896d-41f1d399d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abba68fa-b77b-4e73-874c-09de101156dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7bdb0c9-b976-4f47-a269-fad6740adfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1244220, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9617591-66d5-49a8-9010-b68dcb346fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3497, 3485, 4137, 7002, 4278, 1538, 1605])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9179976-3e29-4855-b206-da4ae36c81d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 7, 7)              55860     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 7, 28)             4032      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 70)                27720     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 49)                3479      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7980)              399000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 490,091\n",
      "Trainable params: 490,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
    "model.add(LSTM(28, return_sequences=True))\n",
    "model.add(LSTM(70))\n",
    "model.add(Dense(49, activation='relu'))\n",
    "\n",
    "model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf37ecb4-9f95-4daa-ab3b-1b1a49de9c66",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1211/1211 [==============================] - 141s 114ms/step - loss: 7.1253 - accuracy: 0.0143\n",
      "Epoch 2/200\n",
      "1211/1211 [==============================] - 133s 110ms/step - loss: 7.0117 - accuracy: 0.0156\n",
      "Epoch 3/200\n",
      "1211/1211 [==============================] - 131s 108ms/step - loss: 6.8446 - accuracy: 0.0211\n",
      "Epoch 4/200\n",
      "1211/1211 [==============================] - 136s 112ms/step - loss: 6.7545 - accuracy: 0.0260\n",
      "Epoch 5/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 6.6055 - accuracy: 0.0342\n",
      "Epoch 6/200\n",
      "1211/1211 [==============================] - 133s 110ms/step - loss: 6.4822 - accuracy: 0.0413\n",
      "Epoch 7/200\n",
      "1211/1211 [==============================] - 131s 109ms/step - loss: 6.3949 - accuracy: 0.0469\n",
      "Epoch 8/200\n",
      "1211/1211 [==============================] - 132s 109ms/step - loss: 6.3063 - accuracy: 0.0528\n",
      "Epoch 9/200\n",
      "1211/1211 [==============================] - 132s 109ms/step - loss: 6.2341 - accuracy: 0.0582\n",
      "Epoch 10/200\n",
      "1211/1211 [==============================] - 133s 109ms/step - loss: 6.1792 - accuracy: 0.0627\n",
      "Epoch 11/200\n",
      "1211/1211 [==============================] - 135s 112ms/step - loss: 6.1336 - accuracy: 0.0659\n",
      "Epoch 12/200\n",
      "1211/1211 [==============================] - 135s 112ms/step - loss: 6.0948 - accuracy: 0.0688\n",
      "Epoch 13/200\n",
      "1211/1211 [==============================] - 134s 110ms/step - loss: 6.0616 - accuracy: 0.0711\n",
      "Epoch 14/200\n",
      "1211/1211 [==============================] - 134s 111ms/step - loss: 6.0326 - accuracy: 0.0731\n",
      "Epoch 15/200\n",
      "1211/1211 [==============================] - 133s 110ms/step - loss: 6.0076 - accuracy: 0.0750\n",
      "Epoch 16/200\n",
      "1211/1211 [==============================] - 131s 108ms/step - loss: 5.9852 - accuracy: 0.0769\n",
      "Epoch 17/200\n",
      "1211/1211 [==============================] - 133s 110ms/step - loss: 5.9657 - accuracy: 0.0783\n",
      "Epoch 18/200\n",
      "1211/1211 [==============================] - 133s 110ms/step - loss: 5.9480 - accuracy: 0.0795\n",
      "Epoch 19/200\n",
      "1211/1211 [==============================] - 131s 108ms/step - loss: 5.9324 - accuracy: 0.0810\n",
      "Epoch 20/200\n",
      "1211/1211 [==============================] - 135s 112ms/step - loss: 5.9182 - accuracy: 0.0821\n",
      "Epoch 21/200\n",
      "1211/1211 [==============================] - 133s 110ms/step - loss: 5.9052 - accuracy: 0.0832\n",
      "Epoch 22/200\n",
      "1211/1211 [==============================] - 132s 109ms/step - loss: 5.8942 - accuracy: 0.0841\n",
      "Epoch 23/200\n",
      "1211/1211 [==============================] - 132s 109ms/step - loss: 5.8831 - accuracy: 0.0848\n",
      "Epoch 24/200\n",
      "1211/1211 [==============================] - 138s 114ms/step - loss: 5.8736 - accuracy: 0.0854\n",
      "Epoch 25/200\n",
      "1211/1211 [==============================] - 137s 113ms/step - loss: 5.8646 - accuracy: 0.0861\n",
      "Epoch 26/200\n",
      "1211/1211 [==============================] - 137s 113ms/step - loss: 5.8567 - accuracy: 0.0865\n",
      "Epoch 27/200\n",
      "1211/1211 [==============================] - 137s 113ms/step - loss: 5.8490 - accuracy: 0.0872\n",
      "Epoch 28/200\n",
      "1211/1211 [==============================] - 136s 113ms/step - loss: 5.8421 - accuracy: 0.0878\n",
      "Epoch 29/200\n",
      "1211/1211 [==============================] - 136s 112ms/step - loss: 5.8356 - accuracy: 0.0883\n",
      "Epoch 30/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.8298 - accuracy: 0.0887\n",
      "Epoch 31/200\n",
      "1211/1211 [==============================] - 138s 114ms/step - loss: 5.8238 - accuracy: 0.0892\n",
      "Epoch 32/200\n",
      "1211/1211 [==============================] - 137s 113ms/step - loss: 5.8187 - accuracy: 0.0893\n",
      "Epoch 33/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.8134 - accuracy: 0.0900\n",
      "Epoch 34/200\n",
      "1211/1211 [==============================] - 138s 114ms/step - loss: 5.8083 - accuracy: 0.0904\n",
      "Epoch 35/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.8038 - accuracy: 0.0906\n",
      "Epoch 36/200\n",
      "1211/1211 [==============================] - 138s 114ms/step - loss: 5.7996 - accuracy: 0.0909\n",
      "Epoch 37/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.7953 - accuracy: 0.0913\n",
      "Epoch 38/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.7917 - accuracy: 0.0912\n",
      "Epoch 39/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.7878 - accuracy: 0.0920\n",
      "Epoch 40/200\n",
      "1211/1211 [==============================] - 140s 116ms/step - loss: 5.7843 - accuracy: 0.0921\n",
      "Epoch 41/200\n",
      "1211/1211 [==============================] - 140s 115ms/step - loss: 5.7806 - accuracy: 0.0923\n",
      "Epoch 42/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.7773 - accuracy: 0.0925\n",
      "Epoch 43/200\n",
      "1211/1211 [==============================] - 140s 115ms/step - loss: 5.7744 - accuracy: 0.0927\n",
      "Epoch 44/200\n",
      "1211/1211 [==============================] - 140s 115ms/step - loss: 5.7713 - accuracy: 0.0930\n",
      "Epoch 45/200\n",
      "1211/1211 [==============================] - 140s 116ms/step - loss: 5.7681 - accuracy: 0.0932\n",
      "Epoch 46/200\n",
      "1211/1211 [==============================] - 140s 116ms/step - loss: 5.7653 - accuracy: 0.0935\n",
      "Epoch 47/200\n",
      "1211/1211 [==============================] - 141s 117ms/step - loss: 5.7623 - accuracy: 0.0935\n",
      "Epoch 48/200\n",
      "1211/1211 [==============================] - 142s 118ms/step - loss: 5.7598 - accuracy: 0.0940\n",
      "Epoch 49/200\n",
      "1211/1211 [==============================] - 140s 115ms/step - loss: 5.7564 - accuracy: 0.0941\n",
      "Epoch 50/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.7534 - accuracy: 0.0942\n",
      "Epoch 51/200\n",
      "1211/1211 [==============================] - 144s 119ms/step - loss: 5.7504 - accuracy: 0.0944\n",
      "Epoch 52/200\n",
      "1211/1211 [==============================] - 145s 119ms/step - loss: 5.7479 - accuracy: 0.0947\n",
      "Epoch 53/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.7451 - accuracy: 0.0949\n",
      "Epoch 54/200\n",
      "1211/1211 [==============================] - 145s 120ms/step - loss: 5.7426 - accuracy: 0.0951\n",
      "Epoch 55/200\n",
      "1211/1211 [==============================] - 142s 118ms/step - loss: 5.7399 - accuracy: 0.0952\n",
      "Epoch 56/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.7377 - accuracy: 0.0954\n",
      "Epoch 57/200\n",
      "1211/1211 [==============================] - 145s 120ms/step - loss: 5.7353 - accuracy: 0.0957\n",
      "Epoch 58/200\n",
      "1211/1211 [==============================] - 147s 122ms/step - loss: 5.7324 - accuracy: 0.0959\n",
      "Epoch 59/200\n",
      "1211/1211 [==============================] - 145s 120ms/step - loss: 5.7298 - accuracy: 0.0961\n",
      "Epoch 60/200\n",
      "1211/1211 [==============================] - 146s 121ms/step - loss: 5.7276 - accuracy: 0.0963\n",
      "Epoch 61/200\n",
      "1211/1211 [==============================] - 147s 121ms/step - loss: 5.7251 - accuracy: 0.0964\n",
      "Epoch 62/200\n",
      "1211/1211 [==============================] - 144s 119ms/step - loss: 5.7226 - accuracy: 0.0968\n",
      "Epoch 63/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.7204 - accuracy: 0.0968\n",
      "Epoch 64/200\n",
      "1211/1211 [==============================] - 140s 115ms/step - loss: 5.7187 - accuracy: 0.0970\n",
      "Epoch 65/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.7168 - accuracy: 0.0971\n",
      "Epoch 66/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.7145 - accuracy: 0.0973\n",
      "Epoch 67/200\n",
      "1211/1211 [==============================] - 139s 115ms/step - loss: 5.7128 - accuracy: 0.0973\n",
      "Epoch 68/200\n",
      "1211/1211 [==============================] - 139s 114ms/step - loss: 5.7107 - accuracy: 0.0974\n",
      "Epoch 69/200\n",
      "1211/1211 [==============================] - 140s 115ms/step - loss: 5.7091 - accuracy: 0.0977\n",
      "Epoch 70/200\n",
      "1211/1211 [==============================] - 140s 116ms/step - loss: 5.7074 - accuracy: 0.0978\n",
      "Epoch 71/200\n",
      "1211/1211 [==============================] - 141s 116ms/step - loss: 5.7059 - accuracy: 0.0980\n",
      "Epoch 72/200\n",
      "1211/1211 [==============================] - 141s 116ms/step - loss: 5.7042 - accuracy: 0.0981\n",
      "Epoch 73/200\n",
      "1211/1211 [==============================] - 140s 116ms/step - loss: 5.7024 - accuracy: 0.0984\n",
      "Epoch 74/200\n",
      "1211/1211 [==============================] - 140s 115ms/step - loss: 5.7010 - accuracy: 0.0984\n",
      "Epoch 75/200\n",
      "1211/1211 [==============================] - 138s 114ms/step - loss: 5.6994 - accuracy: 0.0985\n",
      "Epoch 76/200\n",
      "1211/1211 [==============================] - 141s 116ms/step - loss: 5.6982 - accuracy: 0.0987\n",
      "Epoch 77/200\n",
      "1211/1211 [==============================] - 140s 116ms/step - loss: 5.6963 - accuracy: 0.0988\n",
      "Epoch 78/200\n",
      "1211/1211 [==============================] - 140s 116ms/step - loss: 5.6951 - accuracy: 0.0989\n",
      "Epoch 79/200\n",
      "1211/1211 [==============================] - 141s 117ms/step - loss: 5.6937 - accuracy: 0.0989\n",
      "Epoch 80/200\n",
      "1211/1211 [==============================] - 141s 116ms/step - loss: 5.6922 - accuracy: 0.0990\n",
      "Epoch 81/200\n",
      "1211/1211 [==============================] - 140s 115ms/step - loss: 5.6910 - accuracy: 0.0993\n",
      "Epoch 82/200\n",
      "1211/1211 [==============================] - 141s 116ms/step - loss: 5.6897 - accuracy: 0.0994\n",
      "Epoch 83/200\n",
      "1211/1211 [==============================] - 144s 119ms/step - loss: 5.6882 - accuracy: 0.0995\n",
      "Epoch 84/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.6874 - accuracy: 0.0995\n",
      "Epoch 85/200\n",
      "1211/1211 [==============================] - 141s 116ms/step - loss: 5.6859 - accuracy: 0.0996\n",
      "Epoch 86/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.6846 - accuracy: 0.0997\n",
      "Epoch 87/200\n",
      "1211/1211 [==============================] - 142s 118ms/step - loss: 5.6833 - accuracy: 0.0998\n",
      "Epoch 88/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.6825 - accuracy: 0.0999\n",
      "Epoch 89/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.6811 - accuracy: 0.0999\n",
      "Epoch 90/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.6798 - accuracy: 0.1001\n",
      "Epoch 91/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.6788 - accuracy: 0.1000\n",
      "Epoch 92/200\n",
      "1211/1211 [==============================] - 144s 119ms/step - loss: 5.6778 - accuracy: 0.1005\n",
      "Epoch 93/200\n",
      "1211/1211 [==============================] - 145s 120ms/step - loss: 5.6768 - accuracy: 0.1004\n",
      "Epoch 94/200\n",
      "1211/1211 [==============================] - 141s 116ms/step - loss: 5.6757 - accuracy: 0.1003\n",
      "Epoch 95/200\n",
      "1211/1211 [==============================] - 143s 118ms/step - loss: 5.6747 - accuracy: 0.1006\n",
      "Epoch 96/200\n",
      "1211/1211 [==============================] - 145s 120ms/step - loss: 5.6736 - accuracy: 0.1007\n",
      "Epoch 97/200\n",
      "1211/1211 [==============================] - 145s 119ms/step - loss: 5.6728 - accuracy: 0.1007\n",
      "Epoch 98/200\n",
      "1211/1211 [==============================] - 145s 120ms/step - loss: 5.6715 - accuracy: 0.1008\n",
      "Epoch 99/200\n",
      "1211/1211 [==============================] - 146s 120ms/step - loss: 5.6705 - accuracy: 0.1008\n",
      "Epoch 100/200\n",
      "1211/1211 [==============================] - 146s 121ms/step - loss: 5.6698 - accuracy: 0.1008\n",
      "Epoch 101/200\n",
      "1211/1211 [==============================] - 142s 117ms/step - loss: 5.6691 - accuracy: 0.1010\n",
      "Epoch 102/200\n",
      "1211/1211 [==============================] - 145s 120ms/step - loss: 5.6676 - accuracy: 0.1011\n",
      "Epoch 103/200\n",
      "1211/1211 [==============================] - 145s 120ms/step - loss: 5.6671 - accuracy: 0.1010\n",
      "Epoch 104/200\n",
      "1211/1211 [==============================] - 146s 121ms/step - loss: 5.6658 - accuracy: 0.1012\n",
      "Epoch 105/200\n",
      "1211/1211 [==============================] - 146s 121ms/step - loss: 5.6648 - accuracy: 0.1013\n",
      "Epoch 106/200\n",
      "1211/1211 [==============================] - 147s 121ms/step - loss: 5.6643 - accuracy: 0.1015\n",
      "Epoch 107/200\n",
      "1211/1211 [==============================] - 146s 121ms/step - loss: 5.6634 - accuracy: 0.1015\n",
      "Epoch 108/200\n",
      "1211/1211 [==============================] - 149s 123ms/step - loss: 5.6625 - accuracy: 0.1014\n",
      "Epoch 109/200\n",
      "1211/1211 [==============================] - 150s 124ms/step - loss: 5.6614 - accuracy: 0.1014\n",
      "Epoch 110/200\n",
      "1211/1211 [==============================] - 147s 122ms/step - loss: 5.6612 - accuracy: 0.1016\n",
      "Epoch 111/200\n",
      "1211/1211 [==============================] - 147s 122ms/step - loss: 5.6598 - accuracy: 0.1017\n",
      "Epoch 112/200\n",
      "1211/1211 [==============================] - 148s 122ms/step - loss: 5.6591 - accuracy: 0.1018\n",
      "Epoch 113/200\n",
      "1211/1211 [==============================] - 146s 120ms/step - loss: 5.6584 - accuracy: 0.1018\n",
      "Epoch 114/200\n",
      "1211/1211 [==============================] - 149s 123ms/step - loss: 5.6577 - accuracy: 0.1019\n",
      "Epoch 115/200\n",
      "1211/1211 [==============================] - 149s 123ms/step - loss: 5.6570 - accuracy: 0.1021\n",
      "Epoch 116/200\n",
      "1211/1211 [==============================] - 150s 124ms/step - loss: 5.6562 - accuracy: 0.1021\n",
      "Epoch 117/200\n",
      "1211/1211 [==============================] - 150s 124ms/step - loss: 5.6555 - accuracy: 0.1019\n",
      "Epoch 118/200\n",
      "1211/1211 [==============================] - 150s 124ms/step - loss: 5.6545 - accuracy: 0.1022\n",
      "Epoch 119/200\n",
      "1211/1211 [==============================] - 150s 124ms/step - loss: 5.6540 - accuracy: 0.1022\n",
      "Epoch 120/200\n",
      "1211/1211 [==============================] - 147s 122ms/step - loss: 5.6531 - accuracy: 0.1022\n",
      "Epoch 121/200\n",
      "1211/1211 [==============================] - 151s 125ms/step - loss: 5.6524 - accuracy: 0.1021\n",
      "Epoch 122/200\n",
      "1211/1211 [==============================] - 152s 125ms/step - loss: 5.6517 - accuracy: 0.1025\n",
      "Epoch 123/200\n",
      "1211/1211 [==============================] - 153s 126ms/step - loss: 5.6508 - accuracy: 0.1024\n",
      "Epoch 124/200\n",
      "1211/1211 [==============================] - 152s 125ms/step - loss: 5.6503 - accuracy: 0.1026\n",
      "Epoch 125/200\n",
      "1211/1211 [==============================] - 152s 126ms/step - loss: 5.6498 - accuracy: 0.1025\n",
      "Epoch 126/200\n",
      "1211/1211 [==============================] - 153s 126ms/step - loss: 5.6490 - accuracy: 0.1026\n",
      "Epoch 127/200\n",
      "1211/1211 [==============================] - 154s 127ms/step - loss: 5.6486 - accuracy: 0.1027\n",
      "Epoch 128/200\n",
      "1211/1211 [==============================] - 153s 126ms/step - loss: 5.6473 - accuracy: 0.1027\n",
      "Epoch 129/200\n",
      "1211/1211 [==============================] - 153s 127ms/step - loss: 5.6468 - accuracy: 0.1030\n",
      "Epoch 130/200\n",
      "1211/1211 [==============================] - 154s 127ms/step - loss: 5.6467 - accuracy: 0.1028\n",
      "Epoch 131/200\n",
      "1211/1211 [==============================] - 152s 126ms/step - loss: 5.6458 - accuracy: 0.1029\n",
      "Epoch 132/200\n",
      "1211/1211 [==============================] - 153s 126ms/step - loss: 5.6450 - accuracy: 0.1029\n",
      "Epoch 133/200\n",
      "1211/1211 [==============================] - 156s 129ms/step - loss: 5.6444 - accuracy: 0.1029\n",
      "Epoch 134/200\n",
      "1211/1211 [==============================] - 154s 127ms/step - loss: 5.6438 - accuracy: 0.1029\n",
      "Epoch 135/200\n",
      "1211/1211 [==============================] - 154s 128ms/step - loss: 5.6433 - accuracy: 0.1030\n",
      "Epoch 136/200\n",
      "1211/1211 [==============================] - 155s 128ms/step - loss: 5.6426 - accuracy: 0.1033\n",
      "Epoch 137/200\n",
      "1211/1211 [==============================] - 155s 128ms/step - loss: 5.6421 - accuracy: 0.1033\n",
      "Epoch 138/200\n",
      "1211/1211 [==============================] - 156s 129ms/step - loss: 5.6416 - accuracy: 0.1029\n",
      "Epoch 139/200\n",
      "1211/1211 [==============================] - 155s 128ms/step - loss: 5.6409 - accuracy: 0.1033\n",
      "Epoch 140/200\n",
      "1211/1211 [==============================] - 155s 128ms/step - loss: 5.6400 - accuracy: 0.1033\n",
      "Epoch 141/200\n",
      "1211/1211 [==============================] - 156s 129ms/step - loss: 5.6400 - accuracy: 0.1034\n",
      "Epoch 142/200\n",
      "1211/1211 [==============================] - 156s 129ms/step - loss: 5.6392 - accuracy: 0.1034\n",
      "Epoch 143/200\n",
      "1211/1211 [==============================] - 156s 128ms/step - loss: 5.6386 - accuracy: 0.1034\n",
      "Epoch 144/200\n",
      "1211/1211 [==============================] - 156s 128ms/step - loss: 5.6381 - accuracy: 0.1036\n",
      "Epoch 145/200\n",
      "1211/1211 [==============================] - 156s 129ms/step - loss: 5.6375 - accuracy: 0.1036\n",
      "Epoch 146/200\n",
      "1211/1211 [==============================] - 157s 130ms/step - loss: 5.6371 - accuracy: 0.1037\n",
      "Epoch 147/200\n",
      "1211/1211 [==============================] - 158s 131ms/step - loss: 5.6365 - accuracy: 0.1037\n",
      "Epoch 148/200\n",
      "1211/1211 [==============================] - 158s 130ms/step - loss: 5.6360 - accuracy: 0.1035\n",
      "Epoch 149/200\n",
      "1211/1211 [==============================] - 158s 130ms/step - loss: 5.6357 - accuracy: 0.1038\n",
      "Epoch 150/200\n",
      "1211/1211 [==============================] - 158s 131ms/step - loss: 5.6346 - accuracy: 0.1037\n",
      "Epoch 151/200\n",
      "1211/1211 [==============================] - 159s 131ms/step - loss: 5.6346 - accuracy: 0.1036\n",
      "Epoch 152/200\n",
      "1211/1211 [==============================] - 159s 131ms/step - loss: 5.6341 - accuracy: 0.1036\n",
      "Epoch 153/200\n",
      "1211/1211 [==============================] - 159s 131ms/step - loss: 5.6334 - accuracy: 0.1038\n",
      "Epoch 154/200\n",
      "1211/1211 [==============================] - 159s 132ms/step - loss: 5.6332 - accuracy: 0.1039\n",
      "Epoch 155/200\n",
      "1211/1211 [==============================] - 161s 133ms/step - loss: 5.6323 - accuracy: 0.1038\n",
      "Epoch 156/200\n",
      "1211/1211 [==============================] - 162s 134ms/step - loss: 5.6321 - accuracy: 0.1038\n",
      "Epoch 157/200\n",
      "1211/1211 [==============================] - 161s 133ms/step - loss: 5.6314 - accuracy: 0.1040\n",
      "Epoch 158/200\n",
      "1211/1211 [==============================] - 161s 133ms/step - loss: 5.6311 - accuracy: 0.1040\n",
      "Epoch 159/200\n",
      "1211/1211 [==============================] - 162s 134ms/step - loss: 5.6304 - accuracy: 0.1040\n",
      "Epoch 160/200\n",
      "1211/1211 [==============================] - 165s 136ms/step - loss: 5.6300 - accuracy: 0.1040\n",
      "Epoch 161/200\n",
      "1211/1211 [==============================] - 161s 133ms/step - loss: 5.6296 - accuracy: 0.1041\n",
      "Epoch 162/200\n",
      "1211/1211 [==============================] - 157s 130ms/step - loss: 5.6293 - accuracy: 0.1042\n",
      "Epoch 163/200\n",
      "1211/1211 [==============================] - 160s 132ms/step - loss: 5.6287 - accuracy: 0.1043\n",
      "Epoch 164/200\n",
      "1211/1211 [==============================] - 162s 134ms/step - loss: 5.6285 - accuracy: 0.1042\n",
      "Epoch 165/200\n",
      "1211/1211 [==============================] - 163s 134ms/step - loss: 5.6279 - accuracy: 0.1044\n",
      "Epoch 166/200\n",
      "1211/1211 [==============================] - 163s 135ms/step - loss: 5.6272 - accuracy: 0.1042\n",
      "Epoch 167/200\n",
      "1211/1211 [==============================] - 163s 135ms/step - loss: 5.6267 - accuracy: 0.1043\n",
      "Epoch 168/200\n",
      "1211/1211 [==============================] - 166s 137ms/step - loss: 5.6263 - accuracy: 0.1044\n",
      "Epoch 169/200\n",
      "1211/1211 [==============================] - 164s 135ms/step - loss: 5.6262 - accuracy: 0.1043\n",
      "Epoch 170/200\n",
      "1211/1211 [==============================] - 165s 136ms/step - loss: 5.6255 - accuracy: 0.1045\n",
      "Epoch 171/200\n",
      "1211/1211 [==============================] - 164s 136ms/step - loss: 5.6250 - accuracy: 0.1046\n",
      "Epoch 172/200\n",
      "1211/1211 [==============================] - 164s 136ms/step - loss: 5.6248 - accuracy: 0.1047\n",
      "Epoch 173/200\n",
      "1211/1211 [==============================] - 165s 136ms/step - loss: 5.6243 - accuracy: 0.1045\n",
      "Epoch 174/200\n",
      "1211/1211 [==============================] - 164s 136ms/step - loss: 5.6239 - accuracy: 0.1045\n",
      "Epoch 175/200\n",
      "1211/1211 [==============================] - 166s 137ms/step - loss: 5.6236 - accuracy: 0.1046\n",
      "Epoch 176/200\n",
      "1211/1211 [==============================] - 166s 137ms/step - loss: 5.6231 - accuracy: 0.1043\n",
      "Epoch 177/200\n",
      "1211/1211 [==============================] - 168s 138ms/step - loss: 5.6226 - accuracy: 0.1047\n",
      "Epoch 178/200\n",
      "1211/1211 [==============================] - 170s 141ms/step - loss: 5.6221 - accuracy: 0.1046\n",
      "Epoch 179/200\n",
      "1211/1211 [==============================] - 167s 137ms/step - loss: 5.6217 - accuracy: 0.1046\n",
      "Epoch 180/200\n",
      "1211/1211 [==============================] - 165s 136ms/step - loss: 5.6212 - accuracy: 0.1047\n",
      "Epoch 181/200\n",
      "1211/1211 [==============================] - 164s 136ms/step - loss: 5.6210 - accuracy: 0.1047\n",
      "Epoch 182/200\n",
      "1211/1211 [==============================] - 169s 139ms/step - loss: 5.6207 - accuracy: 0.1047\n",
      "Epoch 183/200\n",
      "1211/1211 [==============================] - 169s 140ms/step - loss: 5.6202 - accuracy: 0.1048\n",
      "Epoch 184/200\n",
      "1211/1211 [==============================] - 169s 140ms/step - loss: 5.6198 - accuracy: 0.1047\n",
      "Epoch 185/200\n",
      "1211/1211 [==============================] - 168s 139ms/step - loss: 5.6194 - accuracy: 0.1050\n",
      "Epoch 186/200\n",
      "1211/1211 [==============================] - 175s 145ms/step - loss: 5.6189 - accuracy: 0.1048\n",
      "Epoch 187/200\n",
      "1211/1211 [==============================] - 172s 142ms/step - loss: 5.6186 - accuracy: 0.1050\n",
      "Epoch 188/200\n",
      "1211/1211 [==============================] - 168s 139ms/step - loss: 5.6183 - accuracy: 0.1050\n",
      "Epoch 189/200\n",
      "1211/1211 [==============================] - 170s 141ms/step - loss: 5.6180 - accuracy: 0.1048\n",
      "Epoch 190/200\n",
      "1211/1211 [==============================] - 169s 140ms/step - loss: 5.6174 - accuracy: 0.1051\n",
      "Epoch 191/200\n",
      "1211/1211 [==============================] - 170s 141ms/step - loss: 5.6171 - accuracy: 0.1049\n",
      "Epoch 192/200\n",
      "1211/1211 [==============================] - 171s 141ms/step - loss: 5.6170 - accuracy: 0.1052\n",
      "Epoch 193/200\n",
      "1211/1211 [==============================] - 171s 142ms/step - loss: 5.6163 - accuracy: 0.1051\n",
      "Epoch 194/200\n",
      "1211/1211 [==============================] - 173s 143ms/step - loss: 5.6160 - accuracy: 0.1051\n",
      "Epoch 195/200\n",
      "1211/1211 [==============================] - 178s 147ms/step - loss: 5.6155 - accuracy: 0.1051\n",
      "Epoch 196/200\n",
      "1211/1211 [==============================] - 168s 139ms/step - loss: 5.6153 - accuracy: 0.1053\n",
      "Epoch 197/200\n",
      "1211/1211 [==============================] - 168s 139ms/step - loss: 5.6148 - accuracy: 0.1052\n",
      "Epoch 198/200\n",
      "1211/1211 [==============================] - 169s 139ms/step - loss: 5.6147 - accuracy: 0.1053\n",
      "Epoch 199/200\n",
      "1211/1211 [==============================] - 172s 142ms/step - loss: 5.6144 - accuracy: 0.1051\n",
      "Epoch 200/200\n",
      "1211/1211 [==============================] - 174s 144ms/step - loss: 5.6141 - accuracy: 0.1053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f58d3f86d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=1028, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0e03013-ab66-424d-874b-47b2c09e5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "754d327a-836b-474f-b37f-545b6c1d5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['四望雲天直下低', '牽絲作老翁雞皮']\n",
    "texts = [text_tokenizer(x) for x in texts]\n",
    "texts = np.array(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a59c25b-f86e-4a71-8a99-498260e00ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "afdd91ee-bc7b-4294-ba17-f03a77bc258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.argmax(preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "384c1bb7-1c65-4370-b30a-22b7c01d7b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffd1a3f4-2e44-4c44-b855-08367616bd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(int(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03c15092-e4c1-4994-96f0-81c4a17afe0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'不'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dict[74]['char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d901fb-257b-43ea-b5fc-9ff2df94b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dict[np.random.randint(0, vocabularly_size)]['char'], char_dict[np.random.randint(0, vocabularly_size)]['char'], char_dict[np.random.randint(0, vocabularly_size)]['char'], char_dict[np.random.randint(0, vocabularly_size)]['char'], char_dict[np.random.randint(0, vocabularly_size)]['char'], char_dict[np.random.randint(0, vocabularly_size)]['char'], char_dict[np.random.randint(0, vocabularly_size)]['char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0839f2-8c87-471e-85be-be56fce0d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_generator(model, seed_text):\n",
    "    output_text = [] + text_tokenizer(seed_text)\n",
    "    for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7551b9-62bc-4db2-8604-05101bceb900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
