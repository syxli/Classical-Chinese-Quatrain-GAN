{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46bd839-ee55-4c0d-b1ab-3010e5f9d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c4925515-f426-4c3d-a138-15da9dcd2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry = pd.read_csv('../data/final_quatrains.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50d7e194-bbed-41f7-bc0b-a67f88b9ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pd.read_csv('../data/dictionary_cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5062f358-6fc1-4e55-b5ac-5eae36310f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>澄潭皎鏡石崔巍萬壑千岩暗綠苔林亭自有幽貞趣況複秋深爽氣來</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>憶昔嬌妃在紫宸鉛華不禦得天真霜綃雖似當時態爭奈嬌波不顧人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>刻木牽絲作老翁雞皮鶴發與真同須臾弄罷寂無事還似人生一夢中</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>禁苑秋來爽氣多昆明風動起滄波中流簫鼓誠堪賞詎假橫汾發棹歌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>大殿連雲接爽溪鐘聲還與鼓聲齊長安若問江南事說道風光在水西</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62206</th>\n",
       "      <td>故園東望路漫漫雙袖龍鍾淚不乾馬上相逢無紙筆憑君傳語報平安</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62207</th>\n",
       "      <td>黃沙磧裏客行迷四望雲天直下低爲言地盡天還盡行到安西更向西</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62208</th>\n",
       "      <td>西向輪臺萬里馀也知鄉信日應疎隴山鸚鵡能言語爲報家人數寄書</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62209</th>\n",
       "      <td>朱脣一點桃花殷宿妝嬌羞偏髻鬟細看只似陽臺女醉着莫許歸巫山</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62210</th>\n",
       "      <td>常聞嬴女玉簫臺奏曲情深彩鳳來欲登此地銷歸恨却羨雙飛去不回</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62211 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text\n",
       "0      澄潭皎鏡石崔巍萬壑千岩暗綠苔林亭自有幽貞趣況複秋深爽氣來\n",
       "1      憶昔嬌妃在紫宸鉛華不禦得天真霜綃雖似當時態爭奈嬌波不顧人\n",
       "2      刻木牽絲作老翁雞皮鶴發與真同須臾弄罷寂無事還似人生一夢中\n",
       "3      禁苑秋來爽氣多昆明風動起滄波中流簫鼓誠堪賞詎假橫汾發棹歌\n",
       "4      大殿連雲接爽溪鐘聲還與鼓聲齊長安若問江南事說道風光在水西\n",
       "...                             ...\n",
       "62206  故園東望路漫漫雙袖龍鍾淚不乾馬上相逢無紙筆憑君傳語報平安\n",
       "62207  黃沙磧裏客行迷四望雲天直下低爲言地盡天還盡行到安西更向西\n",
       "62208  西向輪臺萬里馀也知鄉信日應疎隴山鸚鵡能言語爲報家人數寄書\n",
       "62209  朱脣一點桃花殷宿妝嬌羞偏髻鬟細看只似陽臺女醉着莫許歸巫山\n",
       "62210  常聞嬴女玉簫臺奏曲情深彩鳳來欲登此地銷歸恨却羨雙飛去不回\n",
       "\n",
       "[62211 rows x 1 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "029f59a7-9f24-451e-a359-0b33fe015c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char</th>\n",
       "      <th>tone</th>\n",
       "      <th>rime</th>\n",
       "      <th>ipa</th>\n",
       "      <th>tone_class</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>jyutping</th>\n",
       "      <th>hangul</th>\n",
       "      <th>rime_index</th>\n",
       "      <th>meter_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>㕙</td>\n",
       "      <td>平</td>\n",
       "      <td>諄</td>\n",
       "      <td>tshwin</td>\n",
       "      <td>L</td>\n",
       "      <td>jùn</td>\n",
       "      <td>㕙</td>\n",
       "      <td>준</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>㕮</td>\n",
       "      <td>上</td>\n",
       "      <td>麌</td>\n",
       "      <td>pju</td>\n",
       "      <td>X</td>\n",
       "      <td>fǔ</td>\n",
       "      <td>㕮</td>\n",
       "      <td>부</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>㖃</td>\n",
       "      <td>上</td>\n",
       "      <td>厚</td>\n",
       "      <td>huw</td>\n",
       "      <td>X</td>\n",
       "      <td>hǒu</td>\n",
       "      <td>㖃</td>\n",
       "      <td>후</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>㘆</td>\n",
       "      <td>上</td>\n",
       "      <td>海</td>\n",
       "      <td>thoj</td>\n",
       "      <td>X</td>\n",
       "      <td>tái</td>\n",
       "      <td>㘆</td>\n",
       "      <td>대</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>㘱</td>\n",
       "      <td>平</td>\n",
       "      <td>談</td>\n",
       "      <td>tham</td>\n",
       "      <td>L</td>\n",
       "      <td>㘱</td>\n",
       "      <td>㘱</td>\n",
       "      <td>담</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>𩛿</td>\n",
       "      <td>平</td>\n",
       "      <td>清</td>\n",
       "      <td>zjeng</td>\n",
       "      <td>L</td>\n",
       "      <td>𩛿</td>\n",
       "      <td>𩛿</td>\n",
       "      <td>𩛿</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>𩜾</td>\n",
       "      <td>平</td>\n",
       "      <td>仙</td>\n",
       "      <td>tsyen</td>\n",
       "      <td>L</td>\n",
       "      <td>𩜾</td>\n",
       "      <td>𩜾</td>\n",
       "      <td>𩜾</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>𩥇</td>\n",
       "      <td>去</td>\n",
       "      <td>線</td>\n",
       "      <td>trjen</td>\n",
       "      <td>H</td>\n",
       "      <td>𩥇</td>\n",
       "      <td>𩥇</td>\n",
       "      <td>𩥇</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>𩮀</td>\n",
       "      <td>平</td>\n",
       "      <td>東</td>\n",
       "      <td>tsuwng</td>\n",
       "      <td>L</td>\n",
       "      <td>𩮀</td>\n",
       "      <td>𩮀</td>\n",
       "      <td>𩮀</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>𪕋</td>\n",
       "      <td>上</td>\n",
       "      <td>有</td>\n",
       "      <td>ljuw</td>\n",
       "      <td>X</td>\n",
       "      <td>𪕋</td>\n",
       "      <td>𪕋</td>\n",
       "      <td>𪕋</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7980 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     char tone rime     ipa tone_class pinyin jyutping hangul  rime_index  \\\n",
       "0       㕙    平    諄  tshwin          L    jùn        㕙      준           6   \n",
       "1       㕮    上    麌     pju          X     fǔ        㕮      부           4   \n",
       "2       㖃    上    厚     huw          X    hǒu        㖃      후          14   \n",
       "3       㘆    上    海    thoj          X    tái        㘆      대           5   \n",
       "4       㘱    平    談    tham          L      㘱        㘱      담          16   \n",
       "...   ...  ...  ...     ...        ...    ...      ...    ...         ...   \n",
       "7975    𩛿    平    清   zjeng          L      𩛿        𩛿      𩛿          12   \n",
       "7976    𩜾    平    仙   tsyen          L      𩜾        𩜾      𩜾           7   \n",
       "7977    𩥇    去    線   trjen          H      𩥇        𩥇      𩥇           7   \n",
       "7978    𩮀    平    東  tsuwng          L      𩮀        𩮀      𩮀           1   \n",
       "7979    𪕋    上    有    ljuw          X      𪕋        𪕋      𪕋          14   \n",
       "\n",
       "      meter_class  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  \n",
       "...           ...  \n",
       "7975            1  \n",
       "7976            1  \n",
       "7977            0  \n",
       "7978            1  \n",
       "7979            0  \n",
       "\n",
       "[7980 rows x 10 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38de2704-7ea5-40af-a4e8-590d0848ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = {dictionary.char[i]: i for i in range(0,len(dictionary))}\n",
    "char_dict = {i: {'char': dictionary.char[i],\n",
    "                 'tone': dictionary.tone_class[i],\n",
    "                 'rime': dictionary.rime_index[i],\n",
    "                 'meter': dictionary.meter_class[i]\n",
    "                 } for i in range(0,len(dictionary))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "91351f4f-9564-47f3-b371-b3ecd8489206",
   "metadata": {},
   "outputs": [],
   "source": [
    "meters = [\n",
    "    [1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1,\n",
    "     0,0,1,1,0,0,1,\n",
    "     1,1,0,0,0,1,1],\n",
    "    [0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1,\n",
    "     1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1],\n",
    "    [1,1,0,0,0,1,1,\n",
    "     0,0,1,1,0,0,1,\n",
    "     0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1],\n",
    "    [0,0,1,1,0,0,1,\n",
    "     1,1,0,0,0,1,1,\n",
    "     1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1],\n",
    "    [0,0,1,1,0,0,1,\n",
    "     1,1,0,0,0,1,1,\n",
    "     1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1],\n",
    "    [1,1,0,0,0,1,1,\n",
    "     0,0,1,1,0,0,1,\n",
    "     0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1],\n",
    "    [0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1,\n",
    "     1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1],\n",
    "    [1,1,0,0,1,1,0,\n",
    "     0,0,1,1,0,0,1,\n",
    "     0,0,1,1,1,0,0,\n",
    "     1,1,0,0,0,1,1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a57a2345-7a30-48ab-a833-86d898ae8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenizer(text):\n",
    "    return [chars[i] for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fa7334b-5653-4fec-b103-b62ea5748634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_text(tokens):\n",
    "    return ''.join([char_dict[i]['char'] for i in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "666213b4-f933-48dd-a257-f43e4e91f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyme_checker(tokens):\n",
    "    if char_dict[tokens[13]]['rime'] == char_dict[tokens[27]]['rime']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1912f3d8-885f-4503-b7ce-8e1063bf3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_meter(tokens):\n",
    "    return [char_dict[i]['meter'] for i in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1023e812-8367-4756-b3b9-c47cde08084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meter_score(tokens):\n",
    "    meter = [char_dict[i]['meter'] for i in tokens]\n",
    "    scores = []\n",
    "    for n in meters:\n",
    "        scores.append(sum([int(meter[num]==n[num]) for num in n]))\n",
    "    return max(scores)/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "01577822-6a4f-496d-9457-721ead852c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry['tokens'] = poetry['text'].apply(text_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "1af76732-37de-4f55-8ec4-e8961bc0fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry['meter_score'] = poetry['tokens'].apply(meter_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "854c63fc-5cc3-4e30-bcd2-7ff82d5883cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry['rhyme'] = poetry['tokens'].apply(rhyme_checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c03dbbc4-5ff7-4177-9f30-3c47c42bebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "df35bb14-912d-4e7f-b27a-ad9b0b02c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry.to_csv('../data/quatrains_w_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "914fd80d-7480-4125-985f-3c4ab7c86593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, LSTM, GRU, Embedding, Bidirectional\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e6ea7b7b-a8ce-4920-be17-238f37116ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "23c9038a-eaa5-4105-a558-8357ef13b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_append(text):\n",
    "    tokenized = text_tokenizer(text)\n",
    "    j = meter_score(tokenized)\n",
    "    k = rhyme_checker(tokenized)\n",
    "    tokenized.append(j)\n",
    "    tokenized.append(k)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "0478a409-d39c-4da0-a2fe-2ad167192eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3497, 3485, 4137, 7002, 4278, 1538, 1605, 552...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2064, 2534, 1323, 1208, 999, 4802, 1392, 6911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[514, 2654, 3752, 4841, 211, 5096, 5066, 7204,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4400, 5391, 4433, 231, 3722, 3133, 1159, 2526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1164, 3097, 6651, 7211, 2275, 3722, 3410, 700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62206</th>\n",
       "      <td>[2431, 989, 2691, 2648, 6428, 3461, 3461, 7200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62207</th>\n",
       "      <td>[7860, 3185, 4344, 5971, 1380, 5916, 6622, 971...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62208</th>\n",
       "      <td>[6037, 719, 6556, 5294, 5528, 6875, 7478, 111,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62209</th>\n",
       "      <td>[2660, 5210, 67, 7876, 2778, 5381, 3092, 1394,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62210</th>\n",
       "      <td>[1658, 5129, 1332, 1201, 3844, 4693, 5294, 118...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62211 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      [3497, 3485, 4137, 7002, 4278, 1538, 1605, 552...\n",
       "1      [2064, 2534, 1323, 1208, 999, 4802, 1392, 6911...\n",
       "2      [514, 2654, 3752, 4841, 211, 5096, 5066, 7204,...\n",
       "3      [4400, 5391, 4433, 231, 3722, 3133, 1159, 2526...\n",
       "4      [1164, 3097, 6651, 7211, 2275, 3722, 3410, 700...\n",
       "...                                                  ...\n",
       "62206  [2431, 989, 2691, 2648, 6428, 3461, 3461, 7200...\n",
       "62207  [7860, 3185, 4344, 5971, 1380, 5916, 6622, 971...\n",
       "62208  [6037, 719, 6556, 5294, 5528, 6875, 7478, 111,...\n",
       "62209  [2660, 5210, 67, 7876, 2778, 5381, 3092, 1394,...\n",
       "62210  [1658, 5129, 1332, 1201, 3844, 4693, 5294, 118...\n",
       "\n",
       "[62211 rows x 1 columns]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e7105923-9c3f-485f-8039-a510f86020ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Embedding(input_dim=voc_size, output_dim=64))\n",
    "discriminator.add(Bidirectional(LSTM(64)))\n",
    "discriminator.add(Dense(128, activation='relu'))\n",
    "discriminator.add(Dense(64, activation='relu'))\n",
    "discriminator.add(Dense(1))\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "a8ad4a44-268d-4aa7-9ca0-674392664091",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_size = 100\n",
    "seq_len = 28\n",
    "voc_size = 7980\n",
    "generator = Sequential()\n",
    "generator.add(Embedding(voc_size+1, seq_len))\n",
    "generator.add(LSTM(140, return_sequences=True))\n",
    "generator.add(LSTM(70))\n",
    "generator.add(Dense(56, activation='relu'))\n",
    "generator.add(Dense(seq_len, activation='sigmoid'))\n",
    "# generator.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "6e8f6bb3-2176-4ee4-af4c-d5473f8c3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "7eb6437c-906a-4b9a-8460-667483c7b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "27a953a6-db9f-4a8e-896f-3ca95aa4c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "c2bc86af-1e4b-412f-bfa0-4da4787ecfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b973d5ce-7579-4b65-afd5-c40a2aa21cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "f150feb0-2499-4a9d-812e-2adcbd4f81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "2b99c30f-e98d-45f7-b61e-1ec922015cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "1458c143-70f6-4d57-9bb0-85667998bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal(shape=[batch_size, voc_size+1])\n",
    "gen_poems = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "241ddb6c-d892-4ac2-9c8b-68a7f6cd2b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(0, 7980), dtype=float32, numpy=array([], shape=(0, 7980), dtype=float32)>"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea68084b-6dbd-45ed-85fb-151ff1c75c9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GAN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15460/2137241915.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Grab the seprate components\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# For every epcoh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GAN' is not defined"
     ]
    }
   ],
   "source": [
    "# Grab the seprate components\n",
    "generator, discriminator = GAN.layers\n",
    "\n",
    "# For every epcoh\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Currently on Epoch {epoch+1}\")\n",
    "    i = 0\n",
    "    # For every batch in the dataset\n",
    "    for X_batch in dataset:\n",
    "        i=i+1\n",
    "        if i%100 == 0:\n",
    "            print(f\"\\tCurrently on batch number {i} of {len(my_data)//batch_size}\")\n",
    "\n",
    "        ## TRAINING THE DISCRIMINATOR ######\n",
    "\n",
    "        \n",
    "        # Create Noise\n",
    "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "        \n",
    "        # Generate numbers based just on noise input\n",
    "        gen_poems = generator(noise)\n",
    "        \n",
    "        # Append metrics to fake poems so discriminator has more data to work off of\n",
    "        meter_score()\n",
    "        rhyme_checker()     \n",
    "        \n",
    "        # Concatenate Generated Text against the Real Ones\n",
    "        # TO use tf.concat, the data types must match!\n",
    "        X_fake_vs_real = tf.concat([gen_poems, tf.dtypes.cast(X_batch,tf.float32)], axis=0)\n",
    "        \n",
    "        # Targets set to zero for fake text and 1 for real text\n",
    "        y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "        \n",
    "        # This gets rid of a Keras warning\n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        # Train the discriminator on this batch\n",
    "        discriminator.train_on_batch(X_fake_vs_real, y1)\n",
    "        \n",
    "        ## TRAINING THE GENERATOR     ######\n",
    "\n",
    "        # Create some noise\n",
    "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "        \n",
    "        # We want discriminator to belive that fake text are real\n",
    "        y2 = tf.constant([[1.]] * batch_size)\n",
    "        \n",
    "        # Avoids a warning\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        GAN.train_on_batch(noise, y2)\n",
    "        \n",
    "print(\"TRAINING COMPLETE\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac1702-1240-46ed-959a-e2577d5a1ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
